{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## MOTION AMPLIFICATION OF VIDEO FOR DETECTING INCIPENT MECHANICAL FAULTS VISUALLY"
      ],
      "metadata": {
        "id": "rHYTWq_gAW-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREPARATIONS"
      ],
      "metadata": {
        "id": "iABMvXZgBGhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Establishing the File Framework for Electrical Comparison and Analysis"
      ],
      "metadata": {
        "id": "DpYJPw-5Bswc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf motion_magnification_learning-based"
      ],
      "metadata": {
        "id": "fVI8W9uJByD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU5PiR6Di4ag",
        "outputId": "5d1a4c49-42d0-41c8-ebed-aeb66e450a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aerraj/motion_magnification_learning-based.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaM6fn8UTwFv",
        "outputId": "a3c76d2a-4dd0-473c-9937-81d183f2f0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'motion_magnification_learning-based'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 112 (delta 42), reused 33 (delta 31), pack-reused 55\u001b[K\n",
            "Receiving objects: 100% (112/112), 25.41 MiB | 10.34 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd motion_magnification_learning-based"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jykruN2URM8",
        "outputId": "133a13eb-5390-4322-e73d-e184fa914a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/motion_magnification_learning-based\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Configure analysis libraries for conducting simulated assessments on motors, and initialize pre-existing weights for simulating incipient faults"
      ],
      "metadata": {
        "id": "hw9Z_BgsC9e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet -r requirements.txt\n",
        "!pip install --quiet gdown mediapy"
      ],
      "metadata": {
        "id": "vLnEz4OVDDR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4810e017-5881-44f9-f4e9-7dd85359071b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m1.2/1.6 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ZhengPeng7/motion_magnification_learning-based/releases/download/v1.0/magnet_epoch12_loss7.28e-02.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc9S-f1ZG7xP",
        "outputId": "b5819d07-9bc0-4c8e-ee62-0771c9dc68e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-04 07:44:58--  https://github.com/ZhengPeng7/motion_magnification_learning-based/releases/download/v1.0/magnet_epoch12_loss7.28e-02.pth\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/223970988/4e613b00-aa97-11ea-87b4-bef43fcc6281?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240504%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240504T074459Z&X-Amz-Expires=300&X-Amz-Signature=fed920ba5d248af81a46577a264c54cfd77fe892d09ce98097a58c9aac2648d3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=223970988&response-content-disposition=attachment%3B%20filename%3Dmagnet_epoch12_loss7.28e-02.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-04 07:44:59--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/223970988/4e613b00-aa97-11ea-87b4-bef43fcc6281?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240504%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240504T074459Z&X-Amz-Expires=300&X-Amz-Signature=fed920ba5d248af81a46577a264c54cfd77fe892d09ce98097a58c9aac2648d3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=223970988&response-content-disposition=attachment%3B%20filename%3Dmagnet_epoch12_loss7.28e-02.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3528201 (3.4M) [application/octet-stream]\n",
            "Saving to: ‘magnet_epoch12_loss7.28e-02.pth’\n",
            "\n",
            "magnet_epoch12_loss 100%[===================>]   3.36M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-05-04 07:45:00 (270 MB/s) - ‘magnet_epoch12_loss7.28e-02.pth’ saved [3528201/3528201]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from magnet import MagNet\n",
        "from callbacks import gen_state_dict\n",
        "from config import Config\n",
        "\n",
        "\n",
        "# config\n",
        "config = Config()\n",
        "# Load weights\n",
        "weights_path = 'magnet_epoch12_loss7.28e-02.pth'\n",
        "ep = int(weights_path.split('epoch')[-1].split('_')[0])\n",
        "state_dict = gen_state_dict(weights_path)\n",
        "\n",
        "model_test = MagNet().cuda()\n",
        "model_test.load_state_dict(state_dict)\n",
        "model_test.eval()\n",
        "print(\"Loading weights:\", weights_path)"
      ],
      "metadata": {
        "id": "h5ObXHi5DzcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64700f2c-7b0a-4407-8313-e026572b1f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please load train_mf.txt if you want to do training.\n",
            "Loading weights: magnet_epoch12_loss7.28e-02.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESS"
      ],
      "metadata": {
        "id": "-giuclFJELkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_to_be_maged = 'ls.mp4'\n",
        "video_name = file_to_be_maged.split('.')[0]\n",
        "video_format = '.' + file_to_be_maged.split('.')[-1]\n",
        "\n",
        "\n",
        "sh_file = 'VIDEO_NAME={}\\nVIDEO_FORMAT={}'.format(video_name, video_format) + \"\"\"\n",
        "\n",
        "\n",
        "mkdir ${VIDEO_NAME}\n",
        "ffmpeg -i ${VIDEO_NAME}${VIDEO_FORMAT} -f image2 ${VIDEO_NAME}/%06d.png\n",
        "python make_frameACB.py ${VIDEO_NAME}\n",
        "mkdir test_dir\n",
        "mv ${VIDEO_NAME} test_dir\n",
        "\"\"\"\n",
        "with open('test_preproc.sh', 'w') as file:\n",
        "  file.write(sh_file)\n",
        "\n",
        "!bash test_preproc.sh"
      ],
      "metadata": {
        "id": "YCaK7sxvEXIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ceb7ba0-27f5-4b88-f3e6-8137fb0776a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'ls.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp42isom\n",
            "  Duration: 00:00:10.11, start: 0.000000, bitrate: 1738 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv), 848x480, 1546 kb/s, 30 fps, 30 tbr, 90k tbn, 180k tbc (default)\n",
            "    Metadata:\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 192 kb/s (default)\n",
            "    Metadata:\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to 'ls/%06d.png':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp42isom\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: png, rgb24(pc, gbr/unknown/unknown, progressive), 848x480, q=2-31, 200 kb/s, 30 fps, 30 tbn (default)\n",
            "    Metadata:\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 png\n",
            "frame=  302 fps= 30 q=-0.0 Lsize=N/A time=00:00:10.06 bitrate=N/A speed=1.02x    \n",
            "video:98730kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "ACB-Processing on ls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from data import get_gen_ABC, unit_postprocessing, numpy2cuda, resize2d\n",
        "\n",
        "\n",
        "# testsets = '+'.join(['baby', 'guitar', 'gun', 'drone', 'cattoy', 'water'][:])\n",
        "for testset in [video_name]:\n",
        "    dir_results = 'res_' + testset\n",
        "    if not os.path.exists(dir_results):\n",
        "        os.makedirs(dir_results)\n",
        "\n",
        "    config.data_dir = 'test_dir'\n",
        "    data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
        "    print('Number of test image couples:', data_loader.data_len)\n",
        "    vid_size = cv2.imread(data_loader.paths[0]).shape[:2][::-1]\n",
        "\n",
        "    # Test\n",
        "    for amp in [10, 25, 50]:\n",
        "        frames = []\n",
        "        data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
        "        for idx_load in range(0, data_loader.data_len, data_loader.batch_size):\n",
        "            if (idx_load+1) % 100 == 0:\n",
        "                print('{}'.format(idx_load+1), end=', ')\n",
        "            batch_A, batch_B = data_loader.gen_test()\n",
        "            amp_factor = numpy2cuda(amp)\n",
        "            for _ in range(len(batch_A.shape) - len(amp_factor.shape)):\n",
        "                amp_factor = amp_factor.unsqueeze(-1)\n",
        "            with torch.no_grad():\n",
        "                y_hats = model_test(batch_A, batch_B, 0, 0, amp_factor, mode='evaluate')\n",
        "            for y_hat in y_hats:\n",
        "                y_hat = unit_postprocessing(y_hat, vid_size=vid_size)\n",
        "                frames.append(y_hat)\n",
        "                if len(frames) >= data_loader.data_len:\n",
        "                    break\n",
        "            if len(frames) >= data_loader.data_len:\n",
        "                break\n",
        "        data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
        "        frames = [unit_postprocessing(data_loader.gen_test()[0], vid_size=vid_size)] + frames\n",
        "\n",
        "        # Make videos of framesMag\n",
        "        video_dir = os.path.join(dir_results, testset)\n",
        "        if not os.path.exists(video_dir):\n",
        "            os.makedirs(video_dir)\n",
        "        FPS = 30\n",
        "        video_save_path = os.path.join(video_dir, '{}_amp{}{}'.format(testset, amp, video_format))\n",
        "        out = cv2.VideoWriter(\n",
        "            video_save_path,\n",
        "            cv2.VideoWriter_fourcc(*'DIVX'),\n",
        "            FPS, frames[0].shape[-2::-1]\n",
        "        )\n",
        "        for frame in frames:\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "            cv2.putText(frame, 'amp_factor={}'.format(amp), (7, 37),\n",
        "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 0, 255), thickness=2)\n",
        "            out.write(frame)\n",
        "        out.release()\n",
        "        print('{} has been done.'.format(video_save_path))"
      ],
      "metadata": {
        "id": "FTsheECWEqaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee39dfcd-0da0-4ba2-f918-2996d9e9b8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test image couples: 301\n",
            "100, 200, 300, res_ls/ls/ls_amp10.mp4 has been done.\n",
            "100, 200, 300, res_ls/ls/ls_amp25.mp4 has been done.\n",
            "100, 200, 300, res_ls/ls/ls_amp50.mp4 has been done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIMULATION"
      ],
      "metadata": {
        "id": "qJjN49H3Eod9"
      }
    }
  ]
}